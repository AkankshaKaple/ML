{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, accuracy_score\n",
    "import h5py\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "         # Learning Rate\n",
    "        self.l_rate = 0.001\n",
    "         # Total iterations\n",
    "        self.epochs = 1\n",
    "    \n",
    "    def gradient_descent(self, x_train_data, y_train_data):\n",
    "        \n",
    "        layers = [x_train_data.shape[1], 5, 4, 5, 1]\n",
    "        z = 0\n",
    "        w = []\n",
    "        b = []\n",
    "        a = [0] * len(layers)\n",
    "        z = [0] * len(layers)\n",
    "        d_g = [0] * len(layers)\n",
    "        da = [0] * len(layers)\n",
    "        dz = [0] * len(layers)\n",
    "        db = [0] * len(layers)\n",
    "        dw = [0] * len(layers)\n",
    "        \n",
    "        a[0] = x_train_data.T # 12288x209\n",
    "        m = x_train_data.shape[0]\n",
    "        n = x_train_data.shape[1]\n",
    "\n",
    "        for j in range(1, len(layers)):\n",
    "            \n",
    "            w.append(np.random.rand(layers[j], layers[j-1]) * 0.01 ) # 5x12288\n",
    "            b.append(np.zeros(((layers[j], 1)) ))# 5x1\n",
    "                     \n",
    "            print(\"W : \", w[j-1].shape)\n",
    "#             print(\"b : \", b[j].shape)\n",
    "            print(\"a : \", a[j-1].shape)\n",
    "\n",
    "                \n",
    "            for e in range(self.epochs):\n",
    "                \n",
    "                for i in range(1):  \n",
    "                    ########## Forward Propagation ###########\n",
    "                    z[i] = np.dot(w[i], a[i]) + b[i] # 5x209\n",
    "                   \n",
    "                    a[i+1] = 1 / (1 + np.exp(-z[i])) # 5x209\n",
    "                    \n",
    "                    print(\"x_tr : \", x_train_data.shape)\n",
    "                    print(\"z[i] : \",  z[i].shape)\n",
    "                    print(\"a[i+1] : \", a[i+1].shape)\n",
    "\n",
    "                    ######### Backward Propagation ###########\n",
    "                    \n",
    "                    # Derivative of sigmoid function\n",
    "                    # d_g = a * (1 - a)\n",
    "                    d_g[i] =  a[i+1] * (1 -  a[i+1]) \n",
    "                    print(\"d_g : \", d_g[i].shape)\n",
    "                    \n",
    "                      # Loss Funtion\n",
    "                    # da = -(y/a) + ((1-y)/(1-a))\n",
    "                    da[i] =  -(y_train_data.T / a[i+1].T) + ((1 - y_train_data).T / (1 - a[i+1]).T)\n",
    "                    print(\"da_1 : \", da[i].shape)\n",
    "                    \n",
    "                    # dz = da * d_g\n",
    "                    dz[i] = np.dot(da[i], d_g[i]) # 5x209\n",
    "                    print(\"dz : \", dz[i].shape)\n",
    "                    \n",
    "                    #dw = (dz * a) / m\n",
    "                    dw[i] = np.dot(dz[i], a[i].T) / m # 5x12288\n",
    "                    print(\"dw : \", dw[i].shape)\n",
    "                    \n",
    "                    # db = np.sum(dz)\n",
    "                    db[i] = np.sum(dz[i], axis=1, keepdims=True) / m\n",
    "                    print(\"db : \", db[i].shape)\n",
    "                    \n",
    "                    # w = w - alpha * dw\n",
    "                    # b = b - alpha * db\n",
    "#                     w = w.T - (self.l_rate * dw[i]).T\n",
    "#                     b = b.T - (self.l_rate * db[i]).T\n",
    "                    \n",
    "        return da, w, b\n",
    "\n",
    "    # Prediction :\n",
    "    def prediction(self, parameters, x_test_data):\n",
    "        z = np.dot(parameters[0].T, x_test_data.T) + parameters[1] # Z = W*X = (1 x m)\n",
    "        return 1 / 1 + np.exp(-z) #  Activation function = sigmoid(-z) = (1 x m)\n",
    "    \n",
    "def main():   \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib as plt\n",
    "    from pandas.api.types import is_numeric_dtype\n",
    "    import seaborn as sns\n",
    "\n",
    "       \n",
    "\n",
    "    trainfile = 'train_catvnoncat.h5'\n",
    "    testfile = 'test_catvnoncat.h5'\n",
    "\n",
    "    train_dataset = h5py.File(trainfile, \"r\")\n",
    "    test_dataset = h5py.File(testfile, \"r\")\n",
    "\n",
    "\n",
    "    x_train_data = np.reshape(np.array(train_dataset['train_set_x'][:]), (np.array(train_dataset['train_set_x'][:]).shape[0], -1))\n",
    "    y_train_data = (np.array([train_dataset['train_set_y'][:]]))\n",
    "\n",
    "    x_test_data = np.reshape(np.array(test_dataset['test_set_x'][:]), (np.array(test_dataset['test_set_x'][:]).shape[0], -1))\n",
    "    y_test_data = (np.array([test_dataset['test_set_y'][:]]))\n",
    "\n",
    "    print(\"x_train_data : \",x_train_data.shape)\n",
    "    print(\"y_train_data : \",y_train_data.shape)\n",
    "    print(\"x_test_data : \",x_test_data.shape)\n",
    "    print(\"y_test_data : \",y_test_data.shape)\n",
    "    \n",
    "    x_train_data = x_train_data / 255.\n",
    "    x_test_data = x_test_data / 255.\n",
    "    \n",
    "\n",
    "    # Create a class object\n",
    "    nn = NeuralNetwork()\n",
    "\n",
    "    parameters = nn.gradient_descent(x_train_data, y_train_data)\n",
    "    \n",
    "    # parameter stores the value of weights and bais\n",
    "    \n",
    "#     # pred stores the predicted values from test data set\n",
    "#     pred = nn.prediction(parameters, x_test_data) \n",
    "    \n",
    "#      # pred stores the predicted values from train data set\n",
    "#     pred_train= nn.prediction(parameters, x_train_data)  \n",
    "    \n",
    "#     # It calculates the accuracy\n",
    "#     train_accuracy = (100 - np.mean(np.abs(pred_train - y_train_data)) * 100)\n",
    "#     test_accuracy = (100 - np.mean(np.abs(pred - y_test_data)) * 100)\n",
    "\n",
    "#     print(\"train_accuracy = \", train_accuracy)\n",
    "#     print(\"test_accuracy = \", test_accuracy)\n",
    "#     print(\"da = \",parameters[0])\n",
    "#     print(\"da = \",parameters[1])\n",
    "#     print(\"da = \",parameters[2])\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
